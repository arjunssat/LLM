{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low latency Large Language Models (LLMs) are critical in many applications due to the following reasons:\n",
      "\n",
      "1. Real-time interactions: In real-time applications such as online gaming, video conferencing, and live streaming, low latency is crucial for providing a smooth and responsive user experience. High latency can result in delays, causing frustration and negatively impacting user engagement.\n",
      "2. Improved user experience: Low latency LLMs can provide a more seamless and natural user experience, especially in conversational AI applications such as chatbots and virtual assistants. Users expect quick and accurate responses, and high latency can result in slow and unresponsive interactions, leading to user dissatisfaction.\n",
      "3. Increased efficiency: Low latency LLMs can improve the efficiency of applications by reducing the time it takes to process and respond to user requests. This can result in faster response times, increased throughput, and improved overall system performance.\n",
      "4. Competitive advantage: In many industries, low latency can provide a competitive advantage. For example, in financial trading, low latency can enable traders to make faster and more informed decisions, potentially resulting in higher profits.\n",
      "5. Safety and reliability: In safety-critical applications such as autonomous vehicles and medical devices, low latency is essential for ensuring safety and reliability. High latency can result in delays in processing critical information, potentially leading to catastrophic consequences.\n",
      "\n",
      "In summary, low latency LLMs are essential for providing a seamless and responsive user experience, improving efficiency, providing a competitive advantage, and ensuring safety and reliability in critical applications.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key =\"\"\n",
    "\n",
    "client = Groq(\n",
    "    api_key=groq_api_key,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of low latency LLMs\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt injections are a type of attack where an attacker injects malicious code into a program's input prompt, allowing them to execute arbitrary commands on the user's system. Here are some ways to prevent prompt injections:\n",
      "\n",
      "1. Use a secure prompt mechanism: Use a secure prompt mechanism, such as a GUI-based prompt or a secure command-line prompt, to prevent attackers from injecting malicious code into the prompt.\n",
      "2. Validate user input: Validate user input to ensure that it does not contain malicious code. Use techniques such as input filtering, input validation, and output encoding to prevent malicious input from being executed.\n",
      "3. Use a whitelist: Use a whitelist of allowed commands or inputs to prevent malicious commands from being executed.\n",
      "4. Use a sandbox: Run the program in a sandbox environment, which restricts the program's access to system resources and prevents it from executing malicious commands.\n",
      "5. Use a secure coding practice: Use secure coding practices, such as using parameterized queries instead of concatenating user input into SQL queries, to prevent SQL injection attacks.\n",
      "6. Use a web application firewall: Use a web application firewall (WAF) to protect web applications from prompt injection attacks.\n",
      "7. Keep software up to date: Keep software up to date with the latest security patches and updates to prevent known vulnerabilities from being exploited.\n",
      "8. Use a secure communication protocol: Use a secure communication protocol, such as HTTPS, to protect against eavesdropping and man-in-the-middle attacks.\n",
      "9. Use a secure authentication mechanism: Use a secure authentication mechanism, such as two-factor authentication, to prevent unauthorized access to the system.\n",
      "10. Monitor for suspicious activity: Monitor for suspicious activity, such as unexpected user input or attempts to execute unauthorized commands, and respond appropriately to prevent a security breach.\n",
      "11. Use a security information and event management (SIEM) system: Use a SIEM system to monitor for security-related events and respond to security incidents in real-time.\n",
      "12. Use a vulnerability scanner: Use a vulnerability scanner to identify and remediate vulnerabilities in the system that could be exploited by attackers.\n",
      "13. Use a penetration testing tool: Use a penetration testing tool to simulate attacks on the system and identify vulnerabilities that could be exploited by attackers.\n",
      "14. Use a security orchestration, automation, and response (SOAR) tool: Use a SOAR tool to automate security incident response and remediation.\n",
      "15. Educate users: Educate users on the dangers of prompt injections and how to prevent them.\n",
      "\n",
      "It's important to note that prompt injections can be prevented by implementing a combination of these measures, rather than relying on a single solution.\n"
     ]
    }
   ],
   "source": [
    "# testing groq with llama2\n",
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key =\"\"\n",
    "\n",
    "client = Groq(\n",
    "    api_key=groq_api_key,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Suggest me ways to prevent prompt injections\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama2-70b-4096\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein was a German-born physicist who revolutionized the field of physics with his theories on relativity. Born in 1879, Einstein was a sickly child who struggled with learning disabilities. Despite his challenges, he went on to become one of the greatest minds in history.\n",
      "\n",
      "Einstein's most significant contributions to physics include:\n",
      "\n",
      "* **Theory of Relativity:** In 1915, Einstein published his theory of general relativity, which describes gravity as a curvature of spacetime. This theory revolutionized our understanding of the universe and has been widely accepted as one of the most accurate theories in physics.\n",
      "* **Theory of Special Relativity:** In 1905, Einstein published his theory of special relativity, which describes the relationship between space and time. This theory showed that time dilation and mass-energy equivalence are true.\n",
      "* **Photoelectric Effect:** Einstein's explanation of the photoelectric effect in 1905 provided evidence for the quantum nature of light.\n",
      "* **Quantum Theory:** Einstein was a proponent of the quantum theory, which describes the behavior of matter at the atomic level.\n",
      "\n",
      "Einstein's contributions to physics have had a profound impact on our understanding of the universe. He is considered one of the greatest physicists of all time, and his work continues to inspire scientists and thinkers around the world.\n"
     ]
    }
   ],
   "source": [
    "# testing groq with gemma\n",
    "\n",
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key =\"\"\n",
    "\n",
    "client = Groq(\n",
    "    api_key=groq_api_key,\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who is ALbert Einstein?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gemma-7b-it\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
